{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a27177",
   "metadata": {},
   "source": [
    "# Query twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c392cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import TypedDict, Optional, Union\n",
    "from typing_extensions import NotRequired\n",
    "from google.cloud import firestore, storage\n",
    "from jsonschema import validate\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "\n",
    "\n",
    "def get_token():\n",
    "    env_path = os.path.join(os.path.dirname(os.getcwd()),'.env')\n",
    "    env_path = find_dotenv() # automatic find \n",
    "    load_dotenv(env_path)\n",
    "    token = os.getenv('TWITTER_BEARER_TOKEN','Key missing in env settings')\n",
    "    return token\n",
    "\n",
    "\n",
    "class FirestoreLastDate:\n",
    "    def __init__(self) -> None:\n",
    "        self.db = firestore.Client(project=\"wagon-bootcamp-802\")\n",
    "        self.doc_ref = self.db.collection(\"twitter_dates\").document(\"last_date\")\n",
    "\n",
    "    def update_last_date(self, last_date_db: str) -> None:\n",
    "        self.doc_ref.set({\"last_date_db\": last_date_db})  # type: ignore\n",
    "\n",
    "    def read_last_date(self):\n",
    "        last_date = self.doc_ref.get().to_dict()  # type: ignore\n",
    "        if last_date:\n",
    "            return last_date.get(\"last_date_db\")\n",
    "        else:\n",
    "            logging.error(\"Unable to retrieve last date from firestore\")\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "    bearer_token = get_token()\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "class Tweet(TypedDict):\n",
    "    lang: str\n",
    "    created_at: str\n",
    "    id: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "class TweetMeta(TypedDict):\n",
    "    newest_id: str\n",
    "    oldest_id: str\n",
    "    result_count: int\n",
    "    next_token: NotRequired[str]\n",
    "\n",
    "\n",
    "class TwitterApiResponse(TypedDict):\n",
    "    data: list[Tweet]\n",
    "    meta: TweetMeta\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url: str, params: dict) -> TwitterApiResponse:\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    if response.status_code != 200:\n",
    "        logging.error(\"Failed to connect, response different from 200\")\n",
    "    else:\n",
    "        logging.info(\"Successfully connected to twitter API\")\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def query_twitter(\n",
    "    start_time: Optional[str] = None, next_token: Optional[str] = None\n",
    ") -> TwitterApiResponse:\n",
    "    query_params = {\n",
    "        \"query\": \"#F1\",\n",
    "        \"tweet.fields\": \"created_at,lang\",\n",
    "        \"start_time\": start_time,\n",
    "        \"max_results\": \"100\",\n",
    "        \"next_token\": next_token,\n",
    "    }\n",
    "    json_response = connect_to_endpoint(search_url, query_params)\n",
    "    return json_response\n",
    "\n",
    "\n",
    "def fetching_tweets(response: TwitterApiResponse) -> pd.DataFrame:\n",
    "    if response[\"meta\"].get(\"next_token\", None):\n",
    "        df = pd.DataFrame(response[\"data\"])[[\"text\", \"created_at\", \"id\", \"lang\"]]\n",
    "    else:\n",
    "        df = pd.DataFrame(response[\"data\"])[[\"text\", \"created_at\", \"id\", \"lang\"]].iloc[\n",
    "            :-1\n",
    "        ]\n",
    "    df = df[df[\"lang\"] == \"en\"]\n",
    "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "class PusherToGcs:\n",
    "    def __init__(self, bucket_name: str) -> None:\n",
    "        self.client = storage.Client()\n",
    "        self.bucket = self.client.get_bucket(bucket_name)\n",
    "        self.error_bucket = self.client.get_bucket(\"twitter_production_error_bucket\")\n",
    "\n",
    "    def upload_data(self, df: pd.DataFrame, name: str) -> None:\n",
    "        \"\"\"\n",
    "        Loads data into a csv file in gcs\n",
    "\n",
    "        Args :\n",
    "            df : Dataframe to push\n",
    "            name : name that will be the name of the file.csv\n",
    "        \"\"\"\n",
    "\n",
    "        self.bucket.blob(f\"twitter_data/{name}.csv\").upload_from_string(\n",
    "            df.to_csv(index=False, encoding=\"utf-8-sig\"), \"text/csv\"\n",
    "        )\n",
    "\n",
    "    def upload_error_data(\n",
    "        self, json_object: Union[TwitterApiResponse, list], name: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Loads data into a json file in gcs\n",
    "\n",
    "        Args :\n",
    "            json_object : json to push\n",
    "            name : name that will be the name.csv\n",
    "        \"\"\"\n",
    "\n",
    "        self.error_bucket.blob(f\"twitter_data/{name}.json\").upload_from_string(\n",
    "            data=json.dumps(json_object), content_type=\"application/json\"\n",
    "        )\n",
    "\n",
    "\n",
    "twitter_json_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"data\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"lang\": {\"type\": \"string\"},\n",
    "                    \"created_at\": {\"type\": \"string\"},\n",
    "                    \"text\": {\"type\": \"string\"},\n",
    "                    \"id\": {\"type\": \"string\"},\n",
    "                },\n",
    "                \"additionalProperties\": True,\n",
    "                \"required\": [\"lang\", \"created_at\", \"text\", \"id\"],\n",
    "            },\n",
    "        },\n",
    "        \"meta\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"newest_id\": {\"type\": \"string\"},\n",
    "                \"oldest_id\": {\"type\": \"string\"},\n",
    "                \"result_count\": {\"type\": \"number\"},\n",
    "                \"next_token\": {\"type\": \"string\"},\n",
    "            },\n",
    "            \"additionalProperties\": True,\n",
    "            \"required\": [\"newest_id\", \"oldest_id\", \"result_count\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def twitter_update(event, context) -> None:\n",
    "    \"\"\"Triggered from a message on a Cloud Pub/Sub topic.\n",
    "    Args:\n",
    "         event (dict): Event payload.\n",
    "         context (google.cloud.functions.Context): Metadata for the event.\n",
    "    \"\"\"\n",
    "    most_recent_firestore = FirestoreLastDate()\n",
    "    pusher_to_gcs = PusherToGcs(\"raw_data_twitter_bucket\")\n",
    "    most_recent_dt = most_recent_firestore.read_last_date()\n",
    "    response = query_twitter(most_recent_dt)\n",
    "\n",
    "    # Validating twitter API response schema to handle exceptions and investigate\n",
    "    try:\n",
    "        validate(instance=response, schema=twitter_json_schema)\n",
    "    except:\n",
    "        pusher_to_gcs.upload_error_data(\n",
    "            response, f\"raw_error_twitter_format_{most_recent_dt}\"\n",
    "        )\n",
    "    data = pd.DataFrame()\n",
    "    import ipdb; ipdb.set_trace()\n",
    "    while response[\"meta\"].get(\"next_token\", None):\n",
    "        data = data.append(fetching_tweets(response), ignore_index=True)\n",
    "        response = query_twitter(\n",
    "            most_recent_dt, response[\"meta\"].get(\"next_token\", None)\n",
    "        )\n",
    "    data = data.append(fetching_tweets(response), ignore_index=True)\n",
    "    new_last_date = data.iloc[0][\"created_at\"].tz_localize(None).isoformat() + \"Z\"\n",
    "    return data, new_last_date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "b56c0bf8",
=======
   "id": "9bf9ade0",
>>>>>>> a919c47 (Editing Notebook for manual loading)
   "metadata": {},
   "outputs": [],
   "source": [
    "data, new_last_date = twitter_update('a','b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (twitter_env)",
   "language": "python",
   "name": "twitter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
